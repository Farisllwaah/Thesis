\chapter{Conclusions}

\section{Sum of Contributions}


The main contribution of this thesis is a framework for task clustering and workflow partitioning in distributed systems. We have published 10 papers in several top conferences and 3 submitted journal papers. 
\begin{enumerate}
\item We have developed an overhead aware workflow model to investigate the performance of task clustering in distributed environments. We present the overhead characteristics for a wide range of widely used workflows. This overhead analysis and overhead model has been introduced in our publications in our published work \cite{Chen2013a, Chen2011, Chen2013b}. 
\item We have developed partitioning algorithms that use heuristics to divide large-scale workflows into sub-workflows to satisfy resource constraints such as data storage constraint. This work has been published in \cite{Chen2011a, Integration2012}
\item We have built a statistical model to demonstrate that transient failures can have a significant impact on the runtime performance of scientific workflows. We have developed a Maximum Likelihood Estimation based parameter estimation approach to integrate both prior knowledge and runtime feedbacks. We have proposed fault tolerant clustering algorithms to dynamically adjust the task granularity and improve the runtime performance. This work has been published in \cite{Chen2012}. 
\item We have examined the reasons that cause runtime imbalance and dependency imbalance in task clustering. We have proposed quantitative metrics to evaluate the severity of the two imbalance problems and a series of balanced clustering methods to address the load balance problem for five widely used scientific workflows. This work has been published in \cite{Chen2013a, Chen2013b}. 
\item We have developed an innovative workflow simulator called WorkflowSim with the implementation of popular scheduling algorithms and task clustering algorithms. This simulator is published in \cite{WorkflowSim} and it is available in GitHub \cite{WorkflowSim-Github}. 
We have built an open source community for the users and developers of WorkflowSim. The community has attracted 50+ researchers from 20+ counties and it is still growing. 
%\item Using a set of trace-based simulations, we compare the overall performance with existing approaches for a wide range of popular scientific workflows. We show that the proposed approach can provide significant improvement for the application. 
\end{enumerate}



\section{Conclusions and Perspectives}

This thesis has demonstrated the necessity of optimizing task granularity in executing scientific workflows and has proposed and evaluated a series of innovative approaches to address this issue. Our work may inspire other researchers to continue work on this topic.  

For example, in Chapter \ref{chap:partitioning}, we only consider data storage constraints while researchers may extend our work to further consider other resource constraints such as CPU, memory and bandwidth. 

In Chapter \ref{chap:balance},  one may further analyze the imbalance metrics proposed. For instance, the values of these metrics presented in this chapter are not normalized, and thus their values per level (HIFV, HDV, and HRV) are in different scales. Also, one may analyze more workflow applications, particularly the ones with asymmetric structures, to investigate the relationship between workflow structures and the metric values. 

Also, as shown in Figure~\ref{fig:evaluation_vc_genome}, \emph{VC-prior} can generate very large clustered jobs vertically and makes it difficult for horizontal methods to improve further. Therefore, researchers can develop imbalance metrics for \emph{VC-prior} to avoid generating large clustered jobs, i.e., based on the accumulated runtime of tasks in a pipeline. 


As shown in our experiment results, the combination of our balancing methods with vertical clustering have different sensitivity to workflows with distinguished graph structures and runtime distribution. Therefore, a possible future work is the development of a portfolio clustering, which chooses multiple clustering algorithms, and dynamically selects most suitable one according to the dynamic load.

In Chapter \ref{chap:balance}, we demonstrate the performance gain of combining horizontal clustering methods and vertical clustering. It is worthy to combine multiple algorithms together instead of just two and develop a policy engine that iteratively chooses one algorithm from all of the balancing methods based on the imbalance metrics until the performance gain converges. 

Finally, our metrics can be applied to other workflow study areas, such as workflow scheduling where heuristics would either look into the characteristics of the task when it is ready to schedule (local scheduling), or examine the entire workflow (global optimization algorithms). In this work, the impact factor metric only uses a family of tasks that are tightly related or similar to each other. This method represents a new approach to solve the existing problems. 

In Chapter \ref{chap:tolerance}, we only discuss the fault tolerant clustering and apply it to a homogeneous environment. Our work can be combined with fault tolerant scheduling in heterogeneous environments, i.e, a scheduling algorithm that avoids mapping clustered jobs to failure-prone nodes. It is also interesting to combine vertical clustering methods with horizontal clustering methods. For example, we can perform vertical clustering either before or after horizontal clustering, which we believe would bring different performance improvement. 

As shown in our experiments, our dynamic estimation works well under some constraints, which encourages us to improve its performance further. For example, researchers may weight data based on the time it was collected, the closer the more weight on it. 


 