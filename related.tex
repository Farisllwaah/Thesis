\chapter{Related Work}

\textbf{Workflow Management Systems} (WMS) such as Askalon \cite{Wieczorek2005}, Taverna \cite{Oinn2004}, and Pegasus \cite{Deelman2004} are designed to run scientific workflows on distributed environments. DAGs (Directed Acyclic Graph) and other task graph representations are widely used as the programming model for many parallel applications because it is effective in expressing and optimizing irregular computations. 
Moreover, algorithms expressed as DAGs have the potential to alleviate the user from focusing on the architectural issues, while allowing the engine to extract the best performance from the underlying architecture. 
\textbf{Load Balance}. A plethora of balanced scheduling algorithms have been developed in the networking and OS domains. Many of these schedulers have been extended to the hierarchical setting. Lifflander et al. \cite{Lifflander2012} proposed to use work stealing and a hierarchical persistence-based rebalancing algorithm to address the imbalance problem in scheduling. Zheng et al. \cite{Zheng2011} presented an automatic hierarchical load balancing method that overcomes the scalability challenges of centralized schemes and poor solutions of traditional distributed schemas. Compared to them, our work aims to create clustered jobs that have an even distribution in both job runtime and dependency. 

\textbf{Workflow Scheduling}. There have been a considerable amount of work trying to solve workflow-mapping problem using DAG scheduling heuristics such as HEFT \cite{Topcuoglu2002}, Min-Min \cite{Blythe2005}, MaxMin \cite{Braun2001}, MCT \cite{Braun2001}, etc. Duan \cite{Rubing2005} and Wieczorek \cite{Wieczorek2005} have discussed the scheduling and partitioning scientific workflows in dynamic grids. The emergence of cloud computing \cite{Armbrust2009} has made it possible to easily lease large-scale homogeneous computing resources from commercial resource providers and guarantee the quality of services. In our case, since we assume resources are homogeneous, the resource selection is not a major concern and thus the scheduling problem can be simplified as a task clustering problem. 

\textbf{Overhead Analysis}. Overhead analysis \cite{Prodan2008, Prodan2007} is a topic of great interest in the grid community. Stratan \cite{Stratan2008} evaluates workflow engines including DAGMan/Condor and Karajan/Globus in a real-world grid environment. Sonmez \cite{Sonmez2009} investigated the prediction of the queue delay in grids and assessed the performance and benefit of predicting queue delays based on traces gathered from various resource and production grid environments. Prodan \cite{Prodan2008} offers a grid workflow overhead classification and a systematic measurement of overheads. Our work further investigate the major overheads and their relationship with different optimization techniques. 



\textbf{Fault tolerance}. Failure analysis and modeling \cite{Tang1990} presents system characteristics such as error and failure distribution and hazard rates. Schroeder et al. \cite{Schroeder2006} has studied the statistics of the data, including the root cause of failures, the mean time between failures, and the mean time to repair. Sahoo et al. \cite{Sahoo2004} analyzed the empirical and statistical properties of system errors and failures from a network of heterogeneous servers running a diverse workload. Oppenheimer et al. \cite{Oppenheimer2002} analyzed the causes of failures from three large-scale Internet services and the effectiveness of various techniques for preventing and mitigating service failure. McConnel \cite{Mcconnel1979} analyzed the transient errors in computer systems and showed that transient errors follow a Weibull distribution. Benoit \cite{Benoit2010} et al. analyzed the impact of transient and fail-stop failures on the complexity of task graph scheduling. Based on these work, we measure the failure rates in a workflow and then provide dynamic methods to improve task clustering.  

\textbf{Data Transfer}